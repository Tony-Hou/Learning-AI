# 双目感知的意义
## 意义

既然特斯拉、百度/极越已经在一定规模下证明了纯视觉 L2+ (highway/city, FSD) 的可行性，
那为什么还要去研究双目呢？双目、LiDAR 相较于 2M 的 30/60/120 和 8M 的 30/120 的区别是什么？我的看法是：

- 在线：在数据规模有限的情况下，双目和 LiDAR 一样，能快速提升感知性能上限；
- 离线：可用于 auto-label 中的预标注、建图；
- 成本：相较于 LiDAR，在成本上有显著优势；
- 标定：前向标定在流程上也会更简单；
- 架构：双目硬同步 (vision-centeric)，来触发、对齐其他相机，相较于 LiDAR-centeric 更精准。
但是很可惜，基于 DL-Stereo 的方法需要稠密的深度 GT，而现在的 LiDAR 往往只能提供 150m 内的 GT. Livox Tele 的 FoV 较小，
超远处的反射率和点数不足以支撑我们的需求和场景。最终在远距离使用的，还是基于传统特征的稠密/稀疏匹配。
<img width="730" alt="image" src="https://github.com/Tony-Hou/Learning-AI/assets/26059901/6e623c31-7911-47b6-8175-05bd51be2488">
<img width="679" alt="image" src="https://github.com/Tony-Hou/Learning-AI/assets/26059901/8695dc19-e8ba-4870-809f-6d6ba5bac8dd">

## 鉴智
<img width="729" alt="image" src="https://github.com/Tony-Hou/Learning-AI/assets/26059901/abb9b648-ff04-4389-b9cc-16f25c5998d6">
![image](https://github.com/Tony-Hou/Learning-AI/assets/26059901/b68e4b0f-a1e9-4ec5-a7b5-d0dd0af9a7b5)
也有做 MVS 和全向深度估计 Full Surround Monodepth from Multiple Cameras (TRI-ML/VIDAR)

## 维宁尔 (Veoneer)
![image](https://github.com/Tony-Hou/Learning-AI/assets/26059901/33f84491-5984-4844-ab05-a4664b8c4603)
![image](https://github.com/Tony-Hou/Learning-AI/assets/26059901/6445af52-a663-464b-acbc-39b7f6ed8f96)


## 智加
![image](https://github.com/Tony-Hou/Learning-AI/assets/26059901/2ca669e6-99ce-4e05-92f2-55fcf5801dd6)

第一件事是，通过 SGM/optical flow 这些底层特征，识别非标/超宽障碍物。但实践下来，很难简单地与 3D 表达兼容。
我们渐渐地发现，相较于2D 视角，BEV/Occupancy
是一个更优雅的框架去解决这些难题。逻辑上还是相似的，BEV/Occ 仍然需要去表达、解释这些稠密的底层特征和时序特征。
![image](https://github.com/Tony-Hou/Learning-AI/assets/26059901/fe54591c-428d-47c5-9a4a-597870c43fd0)
通过稠密深度图去避让超宽车
![image](https://github.com/Tony-Hou/Learning-AI/assets/26059901/20948891-c06c-40f0-8cbb-21e09bad9787)

通过光流 motion seg 去识别障碍物

第二件事是，仅对 bbox 内的点去做 match，相同精度下仅有 1/2 latency，并能提升远处 recall. 即使在夜晚，我们也能有 300m 的稳定 trakcing.

![image](https://github.com/Tony-Hou/Learning-AI/assets/26059901/c518e731-102d-45d7-9bcd-cc2be2265a3d)

第三件事是，在高分辨图下，动态裁剪 2M 原图，通过一个额外的 2D 检测器以及稀疏匹配，实现远距离小目标 2倍 tracking 性能的提升 (cone, 80m->160m), 
整体感知 tracking 距离从 300m+ 到近 400m.

![image](https://github.com/Tony-Hou/Learning-AI/assets/26059901/19f55541-c8ae-446a-8eb4-f0a7b76a8669)
第四件事是，实现长焦双目。效果显而易见, Z=fb/d. 焦距 f 的提升能够简单而有效地提升远处距离性能。但简单替换相机，
会造成前向盲区过大的问题。在框架上，需要通过广角相机去做车道线等模块。有一定的系统迁移成本。
![image](https://github.com/Tony-Hou/Learning-AI/assets/26059901/0169b28c-8249-4350-948c-0a4284ea2a1a)

上面这些工作，都是在 Xavier 低算力平台下循序渐进的思考和实践。在 Orin 平台下，我们已经渐渐地过渡到视觉 BEV 3D 框架。
但正如图森的分享，在卡车领域里，数以亿计的 2D 数据仍然在和 3D 需求互相融合，继续完善。
后续的实践，是将高分辨率 RoI 双目集成到 BEV 框架中。当有充沛的远距离 GT 数据时，不管是 dense-bev 还是 
sparse query bev，都能看得更远更稳。

稠密的远距离深度难以获取，但稀疏的bbox 标注仍然是可以得到的。所以，DL 下的双目，
可能直接做双目3D检测或者BEV下的3D检测更简单些。

reference:
https://zhuanlan.zhihu.com/p/681075174
